<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel=icon href=data:,%89PNG%0D%0A%1A%0A><link rel=stylesheet href=/style.css><link rel=canonical href=https://siliconsprawl.com/posts/circular-buffers-not-queues/><title>Building Pipelines with Circular Buffers, not Queues</title><meta name=author content="Eli Lindsey"><meta property="og:title" content="Building Pipelines with Circular Buffers, not Queues"><meta property="og:description" content="Structuring programs as pipelines is a nice way to separate business logic and introduce parallelism - if you do it right it gets you both clarity and performance.
Typically this is done by tying threads together with some form of concurrent queue, such as a channel in Golang, ConcurrentLinkedQueue in Java, or concurrent_queue in C++ (Intel TBB or Microsoft PPL).
Using a simple integer pipeline as an example, we&rsquo;ll have an initial phase writing random integers, one phase that multiplies its input by two, one phase that increments its input, and a final phase that prints the result."><meta property="og:type" content="article"><meta property="og:url" content="https://siliconsprawl.com/posts/circular-buffers-not-queues/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-06-15T00:00:00+00:00"><meta property="article:modified_time" content="2020-06-15T00:00:00+00:00"></head><body><header role=banner class=site-header><div class=wrapper><a class=site-title href=https://siliconsprawl.com>silicon_sprawl_</a><nav class=site-nav><a class=page-link href=/about/ title=about>about</a></nav></div></header><main class=page-content><div class=wrapper><article><header class=post-header><h1 class="post-title p-name">Building Pipelines with Circular Buffers, not Queues</h1></header><div class="post-content e-content"><p>Structuring programs as pipelines is a nice way to separate business logic and
introduce parallelism - if you do it right it gets you both clarity and
performance.</p><p>Typically this is done by tying threads together with some form of concurrent
queue, such as a channel in Golang, ConcurrentLinkedQueue in Java, or
concurrent_queue in C++ (Intel TBB or Microsoft PPL).</p><p>Using a simple integer pipeline as an example, we&rsquo;ll have an initial phase
writing random integers, one phase that multiplies its input by two, one phase
that increments its input, and a final phase that prints the result.</p><p>With queues, it would look something like this:</p><p><img src=linear_pipeline.png alt="linear pipeline diagram"></p><p>But the overhead of multiple queues can be quite high and variable, so is often
unacceptable in low-latency programs. An alternative is to use a single
circular buffer and have each thread hold a cursor into it. This pattern has
significantly better behavior on current hardware and requires minimal
synchronization. It&rsquo;s variously known as event sourcing, the LMAX Disruptor, or
&ldquo;that giant circular buffer pattern.&rdquo;</p><p>A shared circular buffer for our example would instead look like this:</p><p><img src=circular_pipeline.png alt="circular pipeline diagram"></p><p>One way to think about this is that we&rsquo;re moving the executor to the data instead
of the data to the executor.</p><p>A few of the advantages:</p><ul><li>Extremely good data locality. The prefetcher will pull data for the next item
into the cache before we need it and we&rsquo;ll keep the CPU well-fed and happy.</li><li>No data needs to be copied between phases, whereas the queue needs a copy
in/out of the queue. As the struct gets large the queue needs to start using
a pointer indirect, which again hurts locality and puts more pressure on the
gc. Since we don&rsquo;t incur any expensive copies, the buffer can continue to store
large structs directly. If our struct is written appropriately we also won&rsquo;t
need to do any expensive clean operation on struct reuse.</li><li>Low contention. Each phase coordinates with a single atomic and one sync
operation can batch multiple items at once (ie. we only do one sync to take
ownership of all queued items for our phase), compared to a queue which
typically must synchronize on each item.</li><li>Very few pointers for the gc to scan, possibly just the pointer to the
circular buffer and pointers between phases. With care we could code it to
generate zero garbage when in steady state.</li><li>Performance is consistent. Where the queue has multiple buffers that need to
be sized, locks that may be contended, etc. it&rsquo;s much easier in the circular
buffer to quantify the total amount of work in the system and the worst-case
performance under full load.</li></ul><p>A very barebones example:</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span><span style=color:#00f>package</span> main
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00f>import</span> (
</span></span><span style=display:flex><span>	<span style=color:#a31515>&#34;fmt&#34;</span>
</span></span><span style=display:flex><span>	<span style=color:#a31515>&#34;math/rand&#34;</span>
</span></span><span style=display:flex><span>	<span style=color:#a31515>&#34;runtime&#34;</span>
</span></span><span style=display:flex><span>	<span style=color:#a31515>&#34;sync/atomic&#34;</span>
</span></span><span style=display:flex><span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00f>type</span> data <span style=color:#00f>struct</span> {
</span></span><span style=display:flex><span>	num <span style=color:#2b91af>int</span>
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00f>type</span> phase <span style=color:#00f>struct</span> {
</span></span><span style=display:flex><span>	_        [7]<span style=color:#2b91af>int64</span> <span style=color:green>// padding
</span></span></span><span style=display:flex><span><span style=color:green></span>	cursor   <span style=color:#2b91af>int64</span>
</span></span><span style=display:flex><span>	_        [7]<span style=color:#2b91af>int64</span> <span style=color:green>// padding
</span></span></span><span style=display:flex><span><span style=color:green></span>	upstream *phase
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00f>const</span> bufSize = 64 <span style=color:green>// must be power of 2
</span></span></span><span style=display:flex><span><span style=color:green></span><span style=color:#00f>const</span> bufMask <span style=color:#2b91af>int64</span> = bufSize - 1
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00f>var</span> circularBuf [bufSize]data
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00f>func</span> runPhase(p *phase, f <span style=color:#00f>func</span>(<span style=color:#2b91af>int64</span>)) {
</span></span><span style=display:flex><span>	curr := int64(0)
</span></span><span style=display:flex><span>	<span style=color:#00f>for</span> {
</span></span><span style=display:flex><span>		upstreamLimit := atomic.LoadInt64(&amp;p.upstream.cursor)
</span></span><span style=display:flex><span>		<span style=color:#00f>for</span> curr != upstreamLimit {
</span></span><span style=display:flex><span>			f(curr&amp;bufMask)
</span></span><span style=display:flex><span>			curr++
</span></span><span style=display:flex><span>		}
</span></span><span style=display:flex><span>		atomic.StoreInt64(&amp;p.cursor, curr)
</span></span><span style=display:flex><span>		runtime.Gosched()
</span></span><span style=display:flex><span>	}
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00f>func</span> runWriter(p *phase) {
</span></span><span style=display:flex><span>	r := rand.New(rand.NewSource(1))
</span></span><span style=display:flex><span>	curr := int64(0)
</span></span><span style=display:flex><span>	<span style=color:#00f>for</span> {
</span></span><span style=display:flex><span>		upstreamLimit := atomic.LoadInt64(&amp;p.upstream.cursor)
</span></span><span style=display:flex><span>		<span style=color:#00f>if</span> curr == upstreamLimit {
</span></span><span style=display:flex><span>			<span style=color:green>// empty buffer
</span></span></span><span style=display:flex><span><span style=color:green></span>			upstreamLimit = curr + bufSize - 1
</span></span><span style=display:flex><span>		}
</span></span><span style=display:flex><span>		<span style=color:#00f>for</span> curr&amp;bufMask != upstreamLimit&amp;bufMask {
</span></span><span style=display:flex><span>			circularBuf[curr&amp;bufMask].num = r.Intn(100)
</span></span><span style=display:flex><span>			curr++
</span></span><span style=display:flex><span>		}
</span></span><span style=display:flex><span>		atomic.StoreInt64(&amp;p.cursor, curr)
</span></span><span style=display:flex><span>		runtime.Gosched()
</span></span><span style=display:flex><span>	}
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#00f>func</span> main() {
</span></span><span style=display:flex><span>	<span style=color:green>// writeRandInt -&gt; multTwo -&gt; addOne -&gt; printResult
</span></span></span><span style=display:flex><span><span style=color:green></span>	<span style=color:#00f>var</span> printResult, addOne, multTwo, writeRandInt phase
</span></span><span style=display:flex><span>	writeRandInt.upstream = &amp;printResult
</span></span><span style=display:flex><span>	printResult.upstream = &amp;addOne
</span></span><span style=display:flex><span>	addOne.upstream = &amp;multTwo
</span></span><span style=display:flex><span>	multTwo.upstream = &amp;writeRandInt
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#00f>go</span> runWriter(&amp;writeRandInt)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#00f>go</span> runPhase(&amp;addOne, <span style=color:#00f>func</span>(i <span style=color:#2b91af>int64</span>) {
</span></span><span style=display:flex><span>		circularBuf[i].num++
</span></span><span style=display:flex><span>	})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#00f>go</span> runPhase(&amp;multTwo, <span style=color:#00f>func</span>(i <span style=color:#2b91af>int64</span>) {
</span></span><span style=display:flex><span>		circularBuf[i].num *= 2
</span></span><span style=display:flex><span>	})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#00f>go</span> runPhase(&amp;printResult, <span style=color:#00f>func</span>(i <span style=color:#2b91af>int64</span>) {
</span></span><span style=display:flex><span>		fmt.Println(circularBuf[i])
</span></span><span style=display:flex><span>	})
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>	<span style=color:#00f>select</span> {} <span style=color:green>// block forever
</span></span></span><span style=display:flex><span><span style=color:green></span>}
</span></span></code></pre></div><p>This code is meant to show off the core concept in the smallest amount of code
possible. Fully building this out you would hide the cursor logic behind a nice
API and the final business logic would look very similar to a queue-based
implementation looping on a consume function.</p><p>A few specific notes about the implementation:</p><ol><li>The cursors are not truncated to the size of the buffer each time they&rsquo;re
incremented, instead they count towards integer max and wrap. This makes it
easy to disambiguate completely empty buffers from completely full buffers.</li><li>The example has no backoff or wait strategy. Busy spin is what you&rsquo;d want
for a high-load, low-latency system, but something that trades a small
amount of performance to let the CPU idle is preferable in other cases. Ideally
this would be implemented with direct calls to gopark/goready, but those aren&rsquo;t
exposed externally by the runtime. A condvar can be used instead.</li><li>The example also has no batching strategy except &ldquo;grab everything
available&rdquo;. This will lead to clumping, but fixing is trivial.</li><li>On x86_64, atomic loads are compiled to <code>mov</code> and atomic stores are compiled
to <code>xchg</code>. arm64 compiles these to <code>ldar</code> and <code>stlr</code> respectively. This is
standard, but was my first time looking at the asm for atomics in golang, so I
was happy to see solid codegen.</li><li>The conditional for the empty queue case in the writer is unfortunate.
Ideally we would write that conditional as straightline code, eg.</li></ol><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span>upstream = atomic.LoadInt64(&amp;p.upstream.cursor)
</span></span><span style=display:flex><span>empty = curr^upstream == 0
</span></span><span style=display:flex><span>upstreamLimit = (upstream * !empty) + ((curr + bufSize - 1) * empty)
</span></span></code></pre></div><p>This would generate a <code>cmp</code> but no <code>jmp</code>. Unfortunately I know of no way to
express this in go, and the optimizer doesn&rsquo;t do it for us. It is a common pattern
in C and other systems programming languages.
Since we know the numbers are positive but we&rsquo;re saving them in 2s complement,
in this case we do have a path to doing this with computation, but it&rsquo;s
silly and mostly academic.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span>upstream := atomic.LoadInt64(&amp;p.upstream.cursor)
</span></span><span style=display:flex><span>notEmpty := curr ^ upstream
</span></span><span style=display:flex><span>upmult := (notEmpty &gt;&gt; 63) - (-notEmpty &gt;&gt; 63)                                                                                                                                                  
</span></span><span style=display:flex><span>upstreamLimit := (upstream * upmult) + ((curr + bufSize - 1) * (^upmult &amp; 1)) 
</span></span></code></pre></div><p>Update: turns out there is a way to express this. At least as of go 1.19, this
generates the assembly I&rsquo;m looking for - straightline code with a <code>cmp</code> but not <code>jmp</code>.</p><div class=highlight><pre tabindex=0 style=background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-go data-lang=go><span style=display:flex><span>upstream := atomic.LoadInt64(&amp;p.upstream.cursor)
</span></span><span style=display:flex><span>empty := int64(0)
</span></span><span style=display:flex><span><span style=color:#00f>if</span> curr^upstream == 0 {
</span></span><span style=display:flex><span>    empty = 1
</span></span><span style=display:flex><span>}
</span></span><span style=display:flex><span>upstreamLimit := (upstream * (empty^1)) + ((curr + bufSize - 1) * empty)
</span></span></code></pre></div><p>One last note: channels in go are deeply integrated with the runtime and do
things like make explicit gopark/goready calls, copy values from one
goroutine&rsquo;s stack directly into another&rsquo;s, etc. You could do a lot worse, and
should make sure they don&rsquo;t fit your needs before rolling your own.</p></div></article></div></main><footer class="site-footer h-card"><div class=wrapper><div class=footer-col-wrapper><div class="footer-col footer-col-1"><a class=u-email href=mailto:eli@siliconsprawl.com>eli@siliconsprawl.com</a></div><div class="footer-col footer-col-2"><ul class=social-media-list><li><a href=https://github.com/elindsey><svg class="svg-icon"><use xlink:href="/social-icons.svg#github"/></svg></a></li><li><a href=https://www.linkedin.com/in/elilind><svg class="svg-icon"><use xlink:href="/social-icons.svg#linkedin"/></svg></a></li><li><a href=https://siliconsprawl.com/feed.xml><svg class="svg-icon"><use xlink:href="/social-icons.svg#rss"/></svg></a></li></ul></div></div></div></footer></body></html>